# PRISMM-Bench: A Benchmark of Peer-Review Gronuded Multimodal Inconsistencies

## Supplementary Material

This repository contains the supplementary material for the PRISMM-Bench paper. It is structured as follows:

- `annotation_app/`: The web-based application we used for the annotation process.
- `annotation_viewer/`: A viewer for the visualizing our dataset.
- `data_sourcing/`: Scripts and tools used for data collection and preprocessing.
- `evaluation_framework/`: Code for evaluating models on the PRISMM-Bench dataset.
- `survey_app/`: The web-based application we used for the human evaluation survey.

We provide a short introduction in how to use each component below.

### Paper Annotation Application

See [annotation_app/README.md](annotation_app/README.md)

### Data Sourcing

- This is a collection of scripts and tools we used for data collection and preprocessing.
- They are in order of processing.

### Evaluation Framework

- See [evaluation_framework/README.md](evaluation_framework/README.md)

### Survey Application

- See [survey_app/README.md](survey_app/README.md)
