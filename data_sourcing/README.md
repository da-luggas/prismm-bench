# Data Sourcing Pipeline

This directory contains a collection of scripts to create a dataset of inconsistencies in scientific papers from ICLR conference reviews. The pipeline processes OpenReview data, detects inconsistencies using LLMs, extracts relevant images, and generates multiple-choice questions.

## Prerequisites

### API Keys
Set the following environment variables or pass them as command-line arguments:

- `OPENREVIEW_USERNAME` and `OPENREVIEW_PASSWORD`: Credentials for OpenReview API
- `OPENAI_API_KEY`: For inconsistency detection (script 02)
- `GEMINI_API_KEY`: For MCQ generation (scripts 04 and 05)

### Directories and Files
Create the following directory structure:

```
data_sourcing/
├── pdf/                    # PDF files of papers
├── images/                 # Extracted images (output from script 03)
├── suppl_images/           # Supplementary images (for script 07)
├── annotations.json        # Initial annotations file
└── inconsistencies.json    # Detected inconsistencies (output from script 02 for ICLR 2025, already included in the repo)
```

### Dependencies
Install required Python packages:

```bash
pip install -r requirements.txt
```

## Pipeline Steps

### Step 1: Download Reviews
Download ICLR 2025 conference reviews from OpenReview.

```bash
python 01_download_reviews.py --username your_username --password your_password --venue-id ICLR.cc/2025/Conference --output-file iclr_2025_raw.pkl
```

**Inputs:**
- OpenReview credentials

**Outputs:**
- `iclr_2025_raw.pkl`: Pickled submissions data

### Step 2: Detect Inconsistencies
Use LLM to detect inconsistencies mentioned in reviews.

```bash
python 02_detect_inconsistencies_llm.py --input-file iclr_2025_raw.pkl --annotations-file ../annotations.json --output-file inconsistencies.json --model mistralai/mistral-nemo --save-every 10
```

**Inputs:**
- `iclr_2025_raw.pkl` (from step 1)
- `../annotations.json` (existing annotations)

**Outputs:**
- `inconsistencies.json`: Detected inconsistencies with metadata

### Step 3: Extract Images from PDFs
Extract image regions from PDFs based on annotation coordinates.

```bash
python 03_extract_images_from_pdf.py --pdf-dir pdf --img-dir images_new --annot-file annotations.json --dpi 144
```

**Inputs:**
- `pdf/` directory with PDF files
- `annotations.json` with image coordinates

**Outputs:**
- `images_new/` directory with extracted PNG images

### Step 4: Generate Multiple Choice Questions
Generate MCQs for detected inconsistencies using Gemini.

```bash
python 04_generate_multiple_choice_questions.py --input-json new_annotations_no_mcq.json --images-dir images --output-json new_annotations_with_mcq.json --question-key default --model gemini-2.5-flash
```

**Inputs:**
- `new_annotations_no_mcq.json`: Annotations without MCQs
- `images/` directory with inconsistency images

**Outputs:**
- `new_annotations_with_mcq.json`: Annotations enriched with MCQs

### Step 5: Multiturn Debiasing
Apply debiasing to MCQs to remove linguistic cues.

```bash
python 05_multiturn_debiasing.py --input-json annotations.json --output-json json_expectation_edit_llama.json --model google/gemini-2.5-flash
```

**Inputs:**
- `annotations.json`: Annotations with initial MCQs

**Outputs:**
- `json_expectation_edit_llama.json`: Debiased MCQs

### Step 6: Extract MinerU Output
Extract figures, tables, and equations from PDFs using MinerU metadata.

First, process PDFs with MinerU to generate the required metadata. Follow the [MinerU quickstart guide](https://opendatalab.github.io/MinerU/usage/quick_usage/#quick-usage-via-command-line) to install MinerU and process your PDFs.

Then extract the elements:

```bash
python 06_extract_mineru_output.py --mineru-dir mineru_output --pdf-dir pdf --output-dir suppl_images --dpi 144
```

**Inputs:**
- `mineru_output/` directory with MinerU JSON files (generated by MinerU)
- `pdf/` directory with PDF files

**Outputs:**
- `suppl_images/` directory with extracted images
- `extracted_metadata.json`: Metadata for extracted elements

### Step 7: Generate Part Matching MCQs
Generate part matching multiple-choice questions.

```bash
python 07_generate_part_matching_mcq.py --annot-dir /path/to/annotation/results --annot-file annotations.json --img-dir suppl_images --out-file annotations_enriched.json
```

**Inputs:**
- Annotation directory with JSON and images

**Outputs:**
- `annotations_enriched.json`: Annotations with part matching MCQs

## Configuration

All scripts support configuration via:
1. Command-line arguments (highest priority)
2. Environment variables (medium priority)
3. Default values (lowest priority)

Use `--help` with any script to see available options:

```bash
python 01_download_reviews.py --help
```

## Environment Variables

Set these in a `.env` file or your shell:

```bash
# OpenReview
OPENREVIEW_USERNAME=your_username
OPENREVIEW_PASSWORD=your_password
VENUE_ID=ICLR.cc/2025/Conference

# API Keys
OPENAI_API_KEY=your_openai_key
GEMINI_API_KEY=your_gemini_key

# File paths
INPUT_FILE=iclr_2025_raw.pkl
OUTPUT_FILE=inconsistencies.json
PDF_DIR=pdf
IMG_DIR=images
ANNOT_FILE=annotations.json

# Models
MODEL=mistralai/mistral-nemo

# Other
DPI=144
SAVE_EVERY=10
```

## Notes

- Scripts 04 and 05 use Gemini API via OpenRouter proxy
- Script 02 uses OpenAI API via OpenRouter
- Ensure PDF files are named `{paper_id}.pdf` in the `pdf/` directory
- The pipeline processes ICLR 2025 data by default, but can be adapted for other conferences
- Some scripts require existing annotation files that are not generated by this pipeline